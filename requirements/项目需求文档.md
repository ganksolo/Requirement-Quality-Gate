# 项目需求文档

- -------------------------------------------------------------------------------

项目文档第一部分：系统产品需求文档 (System PRD)

**项目名称**：Schema-Driven Quality-Gated Graph Workflow（需求质量门禁系统） **版本**：v1.0 **状态**：规划中

**1. 项目综述 (Executive Summary)**

**1.1 背景与痛点**

在当前的研发流程中，PM（产品经理）与 Tech Team（技术团队）之间存在显著的“上游质量”摩擦。主要表现为：

1. **文档质量参差不齐**：需求票（Ticket）经常缺失验收标准（AC）、异常流程或依赖说明，导致研发在评审会上无法进行技术评估，被迫返工。

2. **评审效率低下**：Tech Review 会议经常沦为“需求补全会”，资深技术人员花费大量时间纠正低级文档错误，而非讨论技术方案。

3. **缺乏统一标准**：什么是“好的需求”主要依赖 Tech Lead 的个人感觉，缺乏可执行的量化标准。

**1.2 核心目标**

本项目旨在构建一套**自动化的需求质量门禁系统**，通过工程化手段拦截不合格需求。

- **质量前置**：在进入 Tech Review 之前，通过 AI Agent 对需求进行结构化整理和评分，强制拦截低质量需求。
- **自动化反馈**：为 PM 提供即时、具体的修改建议（如“缺少验收标准”），而非笼统的“写得不好”。
- **降本增效**：减少评审会上的无效沟通，提升一次评审通过率（First-Time Pass Rate）。

**1.3 边界说明 (Scope)**

- **In Scope (做什么)**：

◦ 对 Jira Ticket/PRD 草稿进行结构化清洗。

◦ 基于 Jira 最佳实践进行评分（完整性、逻辑闭环）。

◦ 生成“阻塞项清单”和“修改建议”。

◦ 提供 n8n/Jira 的集成交互。

- **Out of Scope (不做什么)**：

◦ **不替代 PM 决策**：系统不负责决定业务优先级或产品方向。

◦ **不自动生成代码**：系统产出的是“高质量需求文档”，而非技术实现代码。

◦ **不完全替代人工评审**：系统只负责“格式与逻辑完备性”，技术可行性仍需人工评审。

- -------------------------------------------------------------------------------

**2. 用户角色与业务流程 (Roles & Workflow)**

**2.1 核心用户角色**

| 角色 | 痛点 | 系统价值 |
| --- | --- | --- |
| **产品经理 (PM)** | 经常因为漏写细节被研发打回，不仅要重写还要重开会，挫败感强。 | 获得一个 24/7 在线的“写作助手”，在开会前就指出缺失项，避免会上尴尬。 |
| **技术主管 (Tech Lead)** | 厌倦了在评审会上反复问“这个按钮点不动的逻辑是什么？”，浪费时间。 | 系统作为“坏人”挡掉了 80% 的低级错误，参会时只需关注高价值的技术难点。 |
| **平台管理员** | 需要维护一套标准，但很难向所有 PM 宣导。 | 通过配置规则文件（Rubric），将标准代码化，强制全员执行。 |

**2.2 核心业务流程**

1. **提交 (Submit)**：PM 在 Jira 创建 Ticket 或上传 PRD 草稿，触发检查（通过 Webhook 或 n8n）。

2. **结构化 (Structure)**：系统自动将杂乱的文本映射为标准 JSON 结构，识别缺失的模块（如 Edge Cases）。

3. **评分 (Score)**：系统根据预设规则（Feature vs Bug）进行打分，识别阻塞项（Blockers）。

4. **门禁 (Gate)**：

◦ **Pass (✅)**：分数达标且无阻塞项，自动流转状态为 `Ready for Tech Review`。

◦ **Reject (❌)**：未达标，自动评论打回原因（如“缺少验收标准”），并通知 PM 修改。

5. **修正 (Revise)**：PM 根据建议补全信息，再次触发检查。

- -------------------------------------------------------------------------------

**3. 详细功能需求 (Functional Requirements)**

**3.1 模块一：PRD Structuring Agent (结构化引擎)**

**目标**：将非结构化输入转化为标准中间态数据。

- **F1.1 多模态输入清洗**：支持接收纯文本、Markdown、会议录音转录文本，去除无关噪音。
- **F1.2 智能填空**：基于 Pydantic Schema，自动提取 `User Story`、`Acceptance Criteria`、`Edge Cases` 等字段。若原文未提及，**严禁编造**，必须标记为 `missing`。
- **F1.3 澄清提问**：对于缺失的关键信息，生成针对性的澄清问题（Clarification Questions），引导 PM 补充。

**3.2 模块二：Ticket Scoring Agent (评分引擎)**

**目标**：模拟严格的 Tech Lead 进行质量评估。

- **F2.1 维度打分**：支持按“完整性”、“逻辑闭环”、“清晰度”等维度打分（0-100分）。
- **F2.2 阻塞项识别 (Hard Check)**：

◦ 检测到 **缺少验收标准 (Missing AC)** 时，必须标记为 `BLOCKER`。

◦ 检测到 **模糊词汇**（如“优化一下”、“看着办”）时，标记为 `AMBIGUITY`。

- **F2.3 场景化规则**：支持根据 Ticket 类型加载不同规则。例如 `Type=Bug` 时重点检查“复现步骤”，忽略“User Story”。

**3.3 模块三：质量门禁与反馈 (Gating & Feedback)**

**目标**：执行决策并输出人类可读报告。

- **F3.1 硬性拦截**：逻辑为 `IF (score < 阈值 OR blockers > 0) THEN Reject`。此逻辑由代码写死，不可被 AI 忽略。
- **F3.2 结构化报告**：生成Markdown格式的评论，包含：

◦ 综合得分与结论（Pass/Fail）。

◦ 🔴 **必须修复的阻塞项**（Action Items）。

◦ 🟡 **建议优化的非阻塞项**。

**3.4 模块四：集成与交互 (Integration)**

- **F4.1 Jira 集成**：通过 n8n 监听 Jira Webhook，自动读取新 Ticket 内容，并将报告写回评论区。
- **F4.2 逃生通道 (Override)**：允许 Tech Lead 通过特定标签（如 `admin-override`）强制跳过检查，以应对紧急 P0 故障修复。
- -------------------------------------------------------------------------------

**4. 非功能性需求 (Non-functional Requirements)**

1. **响应速度**：从 PM 提交到收到反馈报告，端到端延迟应控制在 **30-60秒** 以内。

2. **准确性 (Evals)**：

◦ 对“明显缺少验收标准”的 Ticket，拦截率需达到 **100%**。

◦ 误判率（将合格需求判为不合格）应低于 **15%**，并提供反馈渠道。

3. **可追溯性**：所有评分记录、原始输入、使用的 Prompt 版本均需持久化存储，便于后续审计和回放。

4. **数据安全**：对输入的敏感信息（如 PII、密码）需在送往 LLM 前进行脱敏处理。

- -------------------------------------------------------------------------------

**5. 验收标准 (Success Metrics)**

| 指标 | 定义 | 目标值 |
| --- | --- | --- |
| **一次评审通过率** | 首次进入 Tech Review 即通过评审的比例。 | > 80% (当前可能 < 50%) |
| **Ticket 返工次数** | 单个需求在 PM 和 Dev 之间来回拉扯的平均次数。 | < 1.5 次 |
| **Tech Team 满意度** | 技术团队对 PRD 质量的主观评分。 | 提升 30% |
- -------------------------------------------------------------------------------